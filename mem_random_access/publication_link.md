this code is used in publication: https://t.me/server_started/23
publication content:

#память  - это сложно

Хотел сделать быстренько пример неочевидного эффекта, который когда-то встретился, но оказалось что его не так просто воспроизвести, как я думал.

Какое-то время по-подбирав действия в основном цикле (https://github.com/ilnurkh/blog/blob/main/mem_random_access/mem_random_access.cpp#L38) вроде и добился нужного примера, но разваливается он достаточно легко (замеры привожу сделанные на ноуе, а на виртуалке из с эпиком - соотношения не соблюлились).

Что делает код в примере
1. В памяти дана "матрица" - пул байтиков на X мб (будут замеры на 1 мб и 128 мб), который представляет собой кучу 64-байтных или 48-байтных объектиков (векторов)
2. "Действие" заключается в том, что выбирается 10к случайных строк из этой матрицы и вычисляется некая операция, зависящая от контента элемнта

Что любопытного в замерах (https://github.com/ilnurkh/blog/blob/main/mem_random_access/report.txt) 

1. на 1 мб пуле всё примерно ожидаемо - работа с 48-байтными объектами быстрее работы с 64-байтными объектами

48: Elapsed q50: 12.945k ticks
64: Elapsed q50: 13.996k ticks

2. а вот на 128мб картина другая: работать с 64-байтными объектами парадаксально быстрее (*)
48: Elapsed q50: 127.124k ticks
64: Elapsed q50: 115.604k ticks

Объяснение наличия разницы (и на порядок бОльшей стоимости вроде бы одинаковых действий) между 1мб и 128мб простое - в случае 1мб "матрица" помещается в кеш процессора (что конечно легко увидеть по perf stat).

А вот возможность замедлится на 48 байтах - более редко обсуждаемый феномен.  Дело в том (**), что размер кеш-линии на цпу - 64 байта. То есть чтения данных для работы с 64-байтными объектами всегда требуют загрузки из ram в процессорные-кеши ровно одной кеш-линии (если конечно объекты лежат выровнено). А в случае с 48-байтными объектами для трёх четвертей объектов будет требоваться чтение из двух кеш-линий - тут и можно найти пространство для замедления.

Кстати, на сколько я понимаю, с точки зрения взаимотношений цпу-рам (а также между любыми кешами в процессоре), минимально оперируемым объектом является кеш-линия целиком (а не байт, как могло бы показаться по определнию "байта").


(*) я тут ещё раз замечу, что это не на любых операциях так происходит, и даже приведённые числа не во всех окружения воспроизводятся, пришлось подбирать . Такой же эффект когда-то ловили со специальным dot-product (на 1-байтовых линейно-компрессированных элементах векторов и ручным кодом с sse/avx), и, емнип, там воспроизводилось надёжнее и с бОльшей разницей
(**) в случае 48 байт больше кеш-миссов, в тех же числах из perf stat

п.с. на гпу размер кеш-линии 128 байт
