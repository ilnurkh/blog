this code is used in publication: https://habr.com/ru/articles/1000192/  https://t.me/server_started/29

publication content: 

Продолжаем цикл #память - это сложно

Недавно "орлиный глаз" (то есть я) заметил, что в std::atomic у методов есть wait/notify методы.
Я думал что std::atomic это сугубо user-space примитивы синхронизации, но согласно cppref (да и быстрым тестам) - оказалось что wait стопает поток. Как указано в cppref - реализация (при наличии поддержки в платформе) предполагает futex системный вызов.
Futex - это специальный набор системных вызовов, которые, упрощённо, работают поверх хеш-таблицы с ключами в виде адресов памяти, а хранить могут очередь тредов, ждущих события.

Таким образом, можно реализовать критическую секцию (мьютекс), по такому алгоритму
- используем atomic-flag, чтобы указать - взята блокировка или нет
- если уже взята - уходим в wait
- при release делаем notify

В удачном случае (когда контеншена на самом деле нет) - нужно делать только 1 системный вызов (notify), что лучше чем posix-мьютексы, требующие двух системных вызовов.

В общем, захотелось мне замерить какой вариант сколько стоит.

[тут](https://github.com/ilnurkh/blog/blob/main/test_locks/test_locks.cpp) код тестовой программы, весь листинг приводить не буду, опишу что происходит

Что измеряем:
- создаём пул данных на 128мб, заполненных "защищённым типом" - лок + payload(1 байт)
- рабочая нагрузка состоит в том чтобы взять 1 такой элемент, заблочить, модифицировать payload, разлочить
- и настройки итерирования - призванные мочь настроить разные аспекты контеншена и объёма работы в рамках одной кеш-линии
- замеры делаются 3 раза:
  - в основном потоке, без всякого contention
  - два потока, первый делает тоже самое что в основном, а второй делает это "со смещением"
  - в замере на двух потоках фактически пересечыения по взятым блокировкам нет (формально это саксесс ветки, но может быть скрытый контеншен из-за соседства данных)
- есть два основных сценария:
    1) потрогать 1 элемент в кеш линии, а два конкурирующих потока работают с разными элементами одной кеш линии
    2) потрогать элементы в разных кеш линиях
- и дополнительный сценарий:
    - потоки обрабатывают пул с разных сторон - первый с начала в конец, а второй с конца в начало
    - этот режим нужен для случаев, когда мы храним не элемент синхронизации, а указатель на него. Таким методом я хочу добиться того, что элементы аллокатором были выделены далеко друг отдруга

Замеряемые варианты:
- TBasicElem - pyaload без блокировки
- TMutexElem - std::mutex в качестве примитива синхронизации
- TMutexPtrElem - std::unique_ptr<std::mutex> - простой и часто используемый способ сделать объект с мьютексом movable (воспроизводит TUtilMutex, который призван был протестирован дефолт из аркадии)
- TAtomicFlagElem - std::atomic<bool>, горячий цикл попыток захватить блокировку
- TAtomicFlagWaitNotify - std::atomic<bool>, но в случае неуспеха вызывается wait, на release всегда вызывается notify. В общем futex
- TAtomicFlagPtrWaitNotify - тоже самое, только std::unique_ptr<std::atomic<bool>> - делаем объект movable

Замерил я в нескольких окружениях
1. на ноуте (причём через wsl). Числа из report.txt, лежащие рядом относятся к этому замеру - буду приводить их

И несколько доп вариаций - для проверки нет ли каких-то системных смещений у первого (всё таки wsl, плюс отсуствие подбора разного, например опций сборки)
2. на виртуалке с эпиком
3. на той же виртуалке, собрав программу `ya make -r`
4. прошлый вариант также замерил в контейнере (который без доп виртаулизации)

Третий вариант был нужен чтобы по быстрому собрать с нужным glibc, плюс удостовериться что не продалбываюсь по крупному с настройками компиляции (кстати, не зря - только так я заметил что в своём скрипте забыл раскомментить после дебага `-O2 -DNDEBUG`). Если кратко по вариантам - принципиальных отличий в поведении нет, буду ориентироваться на замеры в первом окружении. Все времена приводятся в тиках `std::chrono::high_resolution_clock`.

И так, приступаем к интерпретации результатов https://github.com/ilnurkh/blog/blob/main/test_locks/test_locks.cpp 
1. без блокировок TBasicElem. Если обрабатывать 32 байта из кеш линии, то в релизе 1 модификация стоит 0.2-0.6 тиков.
2. если же брать по 1 элементу с кеш линии то стоимость возрастает до 5-6 тиков. Причём примерно такой же результат получается если собираться без флагов оптимизации

> Итого: берём базовую стоимость обработки в 6 тиков, во всех остальных случаях можно считать что это входит в стоимость полезной работы, и будем её вычитать для вычисления стоимости накладных расходов

3. `std::atomic<bool>` - 2 байтовые элементы, при random-read (режим не взаимодействующих кешлиний) - получаем 12 тиков в 1 потоке, и ~14 тиков на двух потоках. То есть можно говорить об удвоении стомости.
3. Стоимость при обработке множества элементов в рамках одной кеш-линии составила 8.8 тиков, и по 9.6 тиков в случае формального контеншена тредов. (Я ожидал увидеть тут большую просадку, возможно эффективно треды смогли перейти в почти непересекающийся режим - один из потоков обогнал второй и далее они не имели контеншена на каждом мелком элементе)

> Итого: в удачном случае горячий атомик флаг даёт накладные в 2-4 тика. Стоит помнить об опасностях горячих циклов - можно получить ситуацию когда тред съедает всё ядро пытаясь захватить лок, и даже не даёт владельцу лока выполнить свою работу. В целом в серверных приложениях имхо стоит с осторожностью юзать горячие проверки - как правило есть работа на других тредах, которую они могут сделать пока текущий будет ждать.

4. Фьютекс (`std::atomic<bool> wait + notify`), лошадка ради которой эта статья родилась. Показывает стоимость в 54-59 тиков (~50 тиков накладных - для простоты). При условии что 1 тред без попутчика выдаёт 20 тиков (14 накладных). Звучит слабо.

Тут я подумал, что ядро может орудовать не кеш линиями а чем-то другим (страницами?), и возможно при работе примерно в одном месте двух потоков, и решил добавить флаг разнонаправленного вычисления. 

5. И действительно, при по настающему не конкурирующем вычислении (за что конкуренция - не очевидно) - получаем те же 20 тиков (14 накладных), что и на одном треде.

> Итого: фьютекс вроде в 3 раза дороже горячего цикла (хотя по факту мы говорим "о +2 двух стоимостях cache-miss"), но зато даёт защиту от ситуаций действительного контеншена - лишние треды не будут есть время ядер и уйдут спать.

6. `std::atomic<bool> ptr wait + notify` - обарачиваем флаг в unique_ptr, теперь наши объекты занимают по 16 байт (из за выравнивания в 8). В основном прямом проходе 22 тика (те же в районе 15 тиков накладных) на 1 треде, и 60-70 на двух тредах (скажем что это 60 накладных)
7. в разнонаправленном вычислении получаем 24-29 тиков (20 накладных)

> Итого: обернуть фьютекс в поинтер даёт ещё 1 базовый кост (видимо это примерно стоимость кеш мисса). Такова стомость, если хочется хранить векторочки из ваших объектов

8. Наконец подтягиваются олды. `std::mutex` - 48 байт размера нашего пейлоуда (40 сам мьютекс, и до 8 из-за alignment вырос размер 1-байтового пейлоуда). Да, позикс-мьютексы по памяти конечно прямо тяжеленькие. В случае работы с не пересекающимися кеш линиями наш результат - 20-30 тиков (~25 накладных). Прямо неплохой результат, причём тут нет нигде просадок до 50+ тиков в любых вариантах - очень стабильно
9. `std::unique_ptr<std::mutex>` - теже 16 байт в векторе (40 на куче тут отложим в сторону), что и в случае с фьютексом за указателем. Стоимость скачет от 25 до 35. (запишем ~30 накладных), и тоже нет особых выбросов в плохую сторону. Тут ещё надо заметить что второй поток часто подороже, так как его элемент часто занимает 2 разных кеш-линии.

> Итого: мьютекс себя показывают нормально, 1-2 базовых коста доп накладных, но зато стабильность. Хоть и надо заплатить памятью.

Общие результаты: Если рассматривать сценарий гранулярных локов (куча небольших объектов, каждый защиён своим локом), то 
1. мьютекс за указателем - неплохой безопасный дефолт, с которого не зазорно начать
2. если начинает поддавливать память (и ненужен movable дефолтный конструктор) - то стоит рассмотреть вариант фьютекса - будет оптимизация памяти и саксес-случаев. Но лучше это делать опираясь на замеры, если окажется что ваш случай имеет немало contention, то можно получить и проигрыш
3. горячие циклы могут ещё немного помочь, об опасностях уже говорил.


